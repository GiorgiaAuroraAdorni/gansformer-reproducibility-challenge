{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Reproducibility_model_trainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "# Reproducibility challenge: Ganformer\n",
        "##Stefano Carlo Lambertenghi, Felix Boelter, Giorgia Aurora Adorni\n",
        "###Training system\n",
        "\n",
        "USE: Allows for training of Stylegan2, Ganformer with simplex attention, Ganformer with duplex attention, \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF_Ce0gGyfaP",
        "outputId": "20310631-4008-42e2-b958-db76192bfeb5"
      },
      "source": [
        "import gdown\n",
        "!gdown https://drive.google.com/uc?id=1MkWKthet1Avnr4NvPifTMjUc3-3vrj39\n",
        "!unzip GANFormer.zip\n",
        "!rm GANFormer.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MkWKthet1Avnr4NvPifTMjUc3-3vrj39\n",
            "To: /content/GANFormer.zip\n",
            "\r  0% 0.00/656k [00:00<?, ?B/s]\r100% 656k/656k [00:00<00:00, 43.9MB/s]\n",
            "Archive:  GANFormer.zip\n",
            "   creating: GANFormer/\n",
            "  inflating: __MACOSX/._GANFormer    \n",
            "   creating: GANFormer/metrics/\n",
            "  inflating: __MACOSX/GANFormer/._metrics  \n",
            "  inflating: GANFormer/dataset_tool.py  \n",
            "  inflating: __MACOSX/GANFormer/._dataset_tool.py  \n",
            "  inflating: GANFormer/run_metrics.py  \n",
            "  inflating: __MACOSX/GANFormer/._run_metrics.py  \n",
            "  inflating: GANFormer/.DS_Store     \n",
            "  inflating: __MACOSX/GANFormer/._.DS_Store  \n",
            "  inflating: GANFormer/Dockerfile    \n",
            "  inflating: __MACOSX/GANFormer/._Dockerfile  \n",
            "  inflating: GANFormer/pretrained_networks.py  \n",
            "  inflating: __MACOSX/GANFormer/._pretrained_networks.py  \n",
            "   creating: GANFormer/training/\n",
            "  inflating: __MACOSX/GANFormer/._training  \n",
            "  inflating: GANFormer/test_nvcc.cu  \n",
            "  inflating: __MACOSX/GANFormer/._test_nvcc.cu  \n",
            "   creating: GANFormer/docs/\n",
            "  inflating: __MACOSX/GANFormer/._docs  \n",
            "  inflating: GANFormer/README.md     \n",
            "  inflating: __MACOSX/GANFormer/._README.md  \n",
            "  inflating: GANFormer/projector.py  \n",
            "  inflating: __MACOSX/GANFormer/._projector.py  \n",
            "  inflating: GANFormer/.gitignore    \n",
            "  inflating: __MACOSX/GANFormer/._.gitignore  \n",
            "  inflating: GANFormer/run_generator.py  \n",
            "  inflating: __MACOSX/GANFormer/._run_generator.py  \n",
            "  inflating: GANFormer/run_projector.py  \n",
            "  inflating: __MACOSX/GANFormer/._run_projector.py  \n",
            "   creating: GANFormer/dnnlib/\n",
            "  inflating: __MACOSX/GANFormer/._dnnlib  \n",
            "  inflating: GANFormer/LICENSE.txt   \n",
            "  inflating: __MACOSX/GANFormer/._LICENSE.txt  \n",
            "  inflating: GANFormer/run_training.py  \n",
            "  inflating: __MACOSX/GANFormer/._run_training.py  \n",
            "  inflating: GANFormer/metrics/precision_recall.py  \n",
            "  inflating: __MACOSX/GANFormer/metrics/._precision_recall.py  \n",
            "  inflating: GANFormer/metrics/linear_separability.py  \n",
            "  inflating: __MACOSX/GANFormer/metrics/._linear_separability.py  \n",
            "  inflating: GANFormer/metrics/frechet_inception_distance.py  \n",
            "  inflating: __MACOSX/GANFormer/metrics/._frechet_inception_distance.py  \n",
            "  inflating: GANFormer/metrics/__init__.py  \n",
            "  inflating: __MACOSX/GANFormer/metrics/.___init__.py  \n",
            "  inflating: GANFormer/metrics/perceptual_path_length.py  \n",
            "  inflating: __MACOSX/GANFormer/metrics/._perceptual_path_length.py  \n",
            "  inflating: GANFormer/metrics/metric_defaults.py  \n",
            "  inflating: __MACOSX/GANFormer/metrics/._metric_defaults.py  \n",
            "  inflating: GANFormer/metrics/metric_base.py  \n",
            "  inflating: __MACOSX/GANFormer/metrics/._metric_base.py  \n",
            "  inflating: GANFormer/metrics/inception_score.py  \n",
            "  inflating: __MACOSX/GANFormer/metrics/._inception_score.py  \n",
            "  inflating: GANFormer/training/misc.py  \n",
            "  inflating: __MACOSX/GANFormer/training/._misc.py  \n",
            "  inflating: GANFormer/training/loss_stylegan2.py  \n",
            "  inflating: __MACOSX/GANFormer/training/._loss_stylegan2.py  \n",
            "  inflating: GANFormer/training/networks_stylegan2.py  \n",
            "  inflating: __MACOSX/GANFormer/training/._networks_stylegan2.py  \n",
            "  inflating: GANFormer/training/__init__.py  \n",
            "  inflating: __MACOSX/GANFormer/training/.___init__.py  \n",
            "  inflating: GANFormer/training/networks_stylegan.py  \n",
            "  inflating: __MACOSX/GANFormer/training/._networks_stylegan.py  \n",
            "  inflating: GANFormer/training/training_loop.py  \n",
            "  inflating: __MACOSX/GANFormer/training/._training_loop.py  \n",
            "  inflating: GANFormer/training/dataset.py  \n",
            "  inflating: __MACOSX/GANFormer/training/._dataset.py  \n",
            "  inflating: GANFormer/training/networks_GANFormer.py  \n",
            "  inflating: __MACOSX/GANFormer/training/._networks_GANFormer.py  \n",
            "  inflating: GANFormer/training/loss.py  \n",
            "  inflating: __MACOSX/GANFormer/training/._loss.py  \n",
            "  inflating: GANFormer/docs/stylegan2-teaser-1024x256.png  \n",
            "  inflating: __MACOSX/GANFormer/docs/._stylegan2-teaser-1024x256.png  \n",
            "  inflating: GANFormer/docs/stylegan2-training-curves.png  \n",
            "  inflating: __MACOSX/GANFormer/docs/._stylegan2-training-curves.png  \n",
            "  inflating: GANFormer/docs/license.html  \n",
            "  inflating: __MACOSX/GANFormer/docs/._license.html  \n",
            "  inflating: GANFormer/docs/versions.html  \n",
            "  inflating: __MACOSX/GANFormer/docs/._versions.html  \n",
            "  inflating: GANFormer/dnnlib/.DS_Store  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/._.DS_Store  \n",
            "  inflating: GANFormer/dnnlib/util.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/._util.py  \n",
            "  inflating: GANFormer/dnnlib/__init__.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/.___init__.py  \n",
            "   creating: GANFormer/dnnlib/tflib/\n",
            "  inflating: __MACOSX/GANFormer/dnnlib/._tflib  \n",
            "   creating: GANFormer/dnnlib/submission/\n",
            "  inflating: __MACOSX/GANFormer/dnnlib/._submission  \n",
            "  inflating: GANFormer/dnnlib/tflib/custom_ops.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/._custom_ops.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/network_old.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/._network_old.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/__init__.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/.___init__.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/autosummary.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/._autosummary.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/tfutil.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/._tfutil.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/network.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/._network.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/optimizer.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/._optimizer.py  \n",
            "   creating: GANFormer/dnnlib/tflib/ops/\n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/._ops  \n",
            "  inflating: GANFormer/dnnlib/submission/submit.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/submission/._submit.py  \n",
            "  inflating: GANFormer/dnnlib/submission/.DS_Store  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/submission/._.DS_Store  \n",
            "   creating: GANFormer/dnnlib/submission/internal/\n",
            "  inflating: __MACOSX/GANFormer/dnnlib/submission/._internal  \n",
            "  inflating: GANFormer/dnnlib/submission/__init__.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/submission/.___init__.py  \n",
            "  inflating: GANFormer/dnnlib/submission/run_context.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/submission/._run_context.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/ops/__init__.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/ops/.___init__.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/ops/upfirdn_2d.cu  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/ops/._upfirdn_2d.cu  \n",
            "  inflating: GANFormer/dnnlib/tflib/ops/fused_bias_act.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/ops/._fused_bias_act.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/ops/upfirdn_2d.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/ops/._upfirdn_2d.py  \n",
            "  inflating: GANFormer/dnnlib/tflib/ops/fused_bias_act.cu  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/tflib/ops/._fused_bias_act.cu  \n",
            "  inflating: GANFormer/dnnlib/submission/internal/local.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/submission/internal/._local.py  \n",
            "  inflating: GANFormer/dnnlib/submission/internal/__init__.py  \n",
            "  inflating: __MACOSX/GANFormer/dnnlib/submission/internal/.___init__.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzDuIoMcqfBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7622b8f9-02ee-4649-c9ae-2cf856991b14"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import gdown\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/GANFormer\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Mounted at /content/drive\n",
            "/content/GANFormer\n",
            "CPU says hello.\n",
            "GPU says hello.\n",
            "Tensorflow version: 1.15.2\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-f3487847-3ffe-c713-4a76-8b1a721b6cb4)\n",
            "GPU Identified at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voSUPwv_rghw",
        "outputId": "49dc035b-9dcb-498a-8b59-d53103476347"
      },
      "source": [
        "#Download cartoonset dataset\n",
        "%cd /content\n",
        "!gdown https://drive.google.com/uc?id=1RVWqZdL4ezyskQTnQZC_ZakjL0MkpZVb\n",
        "!unzip datasets.zip\n",
        "!rm datasets.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RVWqZdL4ezyskQTnQZC_ZakjL0MkpZVb\n",
            "To: /content/datasets.zip\n",
            "100% 66.9M/66.9M [00:00<00:00, 109MB/s] \n",
            "Archive:  datasets.zip\n",
            "  inflating: datasets/custom/custom-r02.tfrecords  \n",
            "  inflating: datasets/custom/custom-r03.tfrecords  \n",
            "  inflating: datasets/custom/custom-r05.tfrecords  \n",
            "  inflating: datasets/custom/custom-r04.tfrecords  \n",
            "  inflating: datasets/custom/custom-r06.tfrecords  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrOjukSN7fya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3986df52-f245-45f7-be6c-c0bb65cac528"
      },
      "source": [
        "!rm -r /content/drive/MyDrive/GAN/00000-GANFormer-custom-1gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/GAN/00000-GANFormer-custom-1gpu': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Kf_LtxgBieT",
        "outputId": "793c4698-d4c3-4d3f-dbab-f4bbec1bede2"
      },
      "source": [
        "%cd /content/GANFormer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GANFormer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2snUQdVFhoiE"
      },
      "source": [
        "# Manually import cartoon dataset\n",
        "def reimport_cartoon_dataset():\n",
        "  %cd ..\n",
        "  #Download training dataset\n",
        "  !gdown https://drive.google.com/uc?id=1WjlrpvRBrDghIfZ35Smrp9nzc9PekAoa\n",
        "  !tar -xvzf cartoonset10k.tgz\n",
        "  !rm  cartoonset10k.tgz\n",
        "  !rm cartoonset10k/*.csv\n",
        "\n",
        "\n",
        "  path = \"/content/cartoonset10k/\"\n",
        "\n",
        "  from fastai.vision import verify_images\n",
        "  verify_images(path, delete=True)\n",
        "\n",
        "  !mkdir -p /content/custom/\n",
        "  path = '/content/cartoonset10k/'\n",
        "  files = os.listdir(path)\n",
        "\n",
        "\n",
        "  def resize():\n",
        "      files = os.listdir(path)\n",
        "      for i in tqdm(range(10000)):\n",
        "        im = Image.open(path + files[i])\n",
        "        imResize = im.resize((64,64), Image.ANTIALIAS)\n",
        "        imResize.save(\"/content/custom/\" + files[i] , 'JPEG')\n",
        "\n",
        "  resize()\n",
        "  !rm -r /content/cartoonset10k/\n",
        "\n",
        "\n",
        "  %cd /content/GANFormer/\n",
        "  !python dataset_tool.py create_from_images /content/datasets/custom /content/custom/\n",
        "  !rm -r /content/custom/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnjJYbV9W2Nl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xCY_BPMPsja"
      },
      "source": [
        "#Import cityscapes dataset\n",
        "def import_cityscapes_dataset():\n",
        "  %cd /content\n",
        "  %mkdir data\n",
        "  %cd data\n",
        "  %mkdir cityscapes\n",
        "  gdown.download(\"https://drive.google.com/uc?id=1t9Qhxm0iHFd3k-xTYEbKosSx_DkyoLLJ\", \"/content/data/cityscapes/cityscapes.zip\",quiet=False)\n",
        "\n",
        "\n",
        "  def unzip(zip, dir):\n",
        "      with zipfile.ZipFile(zip) as zf:\n",
        "          for member in tqdm.tqdm(zf.infolist(), desc = \"Extracting \"):\n",
        "              try:\n",
        "                  zf.extract(member, dir)\n",
        "              except zipfile.error as e:\n",
        "                  pass\n",
        "\n",
        "\n",
        "  import os\n",
        "  import sys\n",
        "  import tqdm\n",
        "  import zipfile\n",
        "  unzip(\"/content/data/cityscapes/cityscapes.zip\", \"/content/data/cityscapes\")\n",
        "\n",
        "  !rm /content/data/cityscapes/cityscapes.zip\n",
        "\n",
        "  import glob\n",
        "  import os\n",
        "  for in_file in glob.glob('./cityscapes/*'):\n",
        "    in_file_name_1 = in_file[:in_file.find('.tfrecords')]\n",
        "    in_file_name_2 = in_file[len(in_file_name_1)+10:in_file.find('of')]\n",
        "    out_file = f'{in_file_name_1[:-2]}{str(in_file_name_2).zfill(2)}.tfrecords' \n",
        "    os.rename(in_file, out_file)\n",
        "    print(out_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEMscuV6qk9u",
        "outputId": "a569c70a-0b42-4da3-fc6d-e38c470d81b8"
      },
      "source": [
        "%cd /content/GANFormer/training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GANFormer/training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSVoMnq1jNE-",
        "outputId": "2611b10e-4ff1-40da-f78a-11924d5770ff"
      },
      "source": [
        "%%writefile training_loop.py\n",
        "\n",
        "# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n",
        "#\n",
        "# This work is made available under the Nvidia Source Code License-NC.\n",
        "# To view a copy of this license, visit\n",
        "# https://nvlabs.github.io/stylegan2/license.html\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from dnnlib.tflib.autosummary import autosummary\n",
        "\n",
        "from training import dataset\n",
        "from training import misc\n",
        "from metrics import metric_base\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Just-in-time processing of training images before feeding them to the networks.\n",
        "\n",
        "def process_reals(x, labels, lod, mirror_augment, drange_data, drange_net):\n",
        "    with tf.name_scope('DynamicRange'):\n",
        "        x = tf.cast(x, tf.float32)\n",
        "        x = misc.adjust_dynamic_range(x, drange_data, drange_net)\n",
        "    if mirror_augment:\n",
        "        with tf.name_scope('MirrorAugment'):\n",
        "            x = tf.where(tf.random_uniform([tf.shape(x)[0]]) < 0.5, x, tf.reverse(x, [3]))\n",
        "    with tf.name_scope('FadeLOD'): # Smooth crossfade between consecutive levels-of-detail.\n",
        "        s = tf.shape(x)\n",
        "        y = tf.reshape(x, [-1, s[1], s[2]//2, 2, s[3]//2, 2])\n",
        "        y = tf.reduce_mean(y, axis=[3, 5], keepdims=True)\n",
        "        y = tf.tile(y, [1, 1, 1, 2, 1, 2])\n",
        "        y = tf.reshape(y, [-1, s[1], s[2], s[3]])\n",
        "        x = tflib.lerp(x, y, lod - tf.floor(lod))\n",
        "    with tf.name_scope('UpscaleLOD'): # Upscale to match the expected input/output size of the networks.\n",
        "        s = tf.shape(x)\n",
        "        factor = tf.cast(2 ** tf.floor(lod), tf.int32)\n",
        "        x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
        "        x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "        x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
        "    return x, labels\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Evaluate time-varying training parameters.\n",
        "\n",
        "def training_schedule(\n",
        "    cur_nimg,\n",
        "    training_set,\n",
        "    lod_initial_resolution  = None,     # Image resolution used at the beginning.\n",
        "    lod_training_kimg       = 600,      # Thousands of real images to show before doubling the resolution.\n",
        "    lod_transition_kimg     = 600,      # Thousands of real images to show when fading in new layers.\n",
        "    minibatch_size_base     = 16,       # Global minibatch size.\n",
        "    minibatch_size_dict     = {},       # Resolution-specific overrides.\n",
        "    minibatch_gpu_base      = 4,        # Number of samples processed at a time by one GPU.\n",
        "    minibatch_gpu_dict      = {},       # Resolution-specific overrides.\n",
        "    G_lrate_base            = 0.002,    # Learning rate for the generator.\n",
        "    G_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    D_lrate_base            = 0.002,    # Learning rate for the discriminator.\n",
        "    D_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    lrate_rampup_kimg       = 0,        # Duration of learning rate ramp-up.\n",
        "    tick_kimg_base          = 160,        # Default interval of progress snapshots.\n",
        "    tick_size          = 16): # Resolution-specific overrides.\n",
        "\n",
        "    # Initialize result dict.\n",
        "    s = dnnlib.EasyDict()\n",
        "    s.kimg = cur_nimg / 1000.0\n",
        "\n",
        "    # Training phase.\n",
        "    phase_dur = lod_training_kimg + lod_transition_kimg\n",
        "    phase_idx = int(np.floor(s.kimg / phase_dur)) if phase_dur > 0 else 0\n",
        "    phase_kimg = s.kimg - phase_idx * phase_dur\n",
        "    # Level-of-detail and resolution.\n",
        "    if lod_initial_resolution is None:\n",
        "        s.lod = 0.0\n",
        "    else:\n",
        "        s.lod = training_set.resolution_log2\n",
        "        s.lod -= np.floor(np.log2(lod_initial_resolution))\n",
        "        s.lod -= phase_idx\n",
        "        if lod_transition_kimg > 0:\n",
        "            s.lod -= max(phase_kimg - lod_training_kimg, 0.0) / lod_transition_kimg\n",
        "        s.lod = max(s.lod, 0.0)\n",
        "    s.resolution = 2 ** (training_set.resolution_log2 - int(np.floor(s.lod)))\n",
        "\n",
        "    # Minibatch size.\n",
        "    s.minibatch_size = minibatch_size_dict.get(s.resolution, minibatch_size_base)\n",
        "    s.minibatch_gpu = minibatch_gpu_dict.get(s.resolution, minibatch_gpu_base)\n",
        "\n",
        "    # Learning rate.\n",
        "    s.G_lrate = G_lrate_dict.get(s.resolution, G_lrate_base)\n",
        "    s.D_lrate = D_lrate_dict.get(s.resolution, D_lrate_base)\n",
        "    if lrate_rampup_kimg > 0:\n",
        "        rampup = min(s.kimg / lrate_rampup_kimg, 1.0)\n",
        "        s.G_lrate *= rampup\n",
        "        s.D_lrate *= rampup\n",
        "\n",
        "    # Other parameters.\n",
        "    s.tick_kimg = tick_size\n",
        "    return s\n",
        "\n",
        "\n",
        "\n",
        "def training_loop(\n",
        "    G_args                  = {},       # Options for generator network.\n",
        "    D_args                  = {},       # Options for discriminator network.\n",
        "    G_opt_args              = {},       # Options for generator optimizer.\n",
        "    D_opt_args              = {},       # Options for discriminator optimizer.\n",
        "    G_loss_args             = {},       # Options for generator loss.\n",
        "    D_loss_args             = {},       # Options for discriminator loss.\n",
        "    dataset_args            = {},       # Options for dataset.load_dataset().\n",
        "    sched_args              = {},       # Options for train.TrainingSchedule.\n",
        "    grid_args               = {},       # Options for train.setup_snapshot_image_grid().\n",
        "    metric_arg_list         = [],       # Options for MetricGroup.\n",
        "    tf_config               = {},       # Options for tflib.init_tf().\n",
        "    data_dir                = None,     # Directory to load datasets from.\n",
        "    G_smoothing_kimg        = 10.0,     # Half-life of the running average of generator weights.\n",
        "    minibatch_repeats       = 4,        # Number of minibatches to run before adjusting training parameters.\n",
        "    lazy_regularization     = True,     # Perform regularization as a separate training step?\n",
        "    G_reg_interval          = 4,        # How often the perform regularization for G? Ignored if lazy_regularization=False.\n",
        "    D_reg_interval          = 16,       # How often the perform regularization for D? Ignored if lazy_regularization=False.\n",
        "    reset_opt_for_new_lod   = True,     # Reset optimizer internal state (e.g. Adam moments) when new layers are introduced?\n",
        "    total_kimg              = 25000,    # Total length of the training, measured in thousands of real images.\n",
        "    mirror_augment          = False,    # Enable mirror augment?\n",
        "    drange_net              = [-1,1],   # Dynamic range used when feeding image data to the networks.\n",
        "    image_snapshot_ticks    = 1,       # How often to save image snapshots? None = only save 'reals.png' and 'fakes-init.png'.\n",
        "    network_snapshot_ticks  = 1,       # How often to save network snapshots? None = only save 'networks-final.pkl'.\n",
        "    save_tf_graph           = False,    # Include full TensorFlow computation graph in the tfevents file?\n",
        "    save_weight_histograms  = False,    # Include weight histograms in the tfevents file?\n",
        "    resume_pkl              = None,     # Network pickle to resume training from, None = train from scratch.\n",
        "    resume_kimg             = 0,      # Assumed training progress at the beginning. Affects reporting and training schedule.\n",
        "    resume_time             = 0.0,      # Assumed wallclock time at the beginning. Affects reporting.\n",
        "    resume_with_new_nets    = False,\n",
        "    tick_size               = 16,\n",
        "    ganformer=True):   # Construct new networks according to G_args and D_args before resuming training?\n",
        "\n",
        "    # Initialize dnnlib and TensorFlow.\n",
        "    tflib.init_tf(tf_config)\n",
        "    num_gpus = dnnlib.submit_config.num_gpus\n",
        "\n",
        "    # Load training set.\n",
        "    training_set = dataset.load_dataset(data_dir=dnnlib.convert_path(data_dir), verbose=True, **dataset_args)\n",
        "    grid_size, grid_reals, grid_labels = misc.setup_snapshot_image_grid(training_set, **grid_args)\n",
        "    misc.save_image_grid(grid_reals, dnnlib.make_run_dir_path('reals.png'), drange=training_set.dynamic_range, grid_size=grid_size)\n",
        "\n",
        "    # Construct or load networks.\n",
        "    with tf.device('/gpu:0'):\n",
        "        if resume_pkl is None or resume_with_new_nets:\n",
        "            print('Constructing networks...')\n",
        "            G = tflib.Network('G', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **G_args)\n",
        "            D = tflib.Network('D', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **D_args)\n",
        "            Gs = G.clone('Gs')\n",
        "        if resume_pkl is not None:\n",
        "            print('Loading networks from \"%s\"...' % resume_pkl)\n",
        "            rG, rD, rGs = misc.load_pkl(resume_pkl)\n",
        "            if resume_with_new_nets: G.copy_vars_from(rG); D.copy_vars_from(rD); Gs.copy_vars_from(rGs)\n",
        "            else: G = rG; D = rD; Gs = rGs\n",
        "\n",
        "    # Print layers and generate initial image snapshot.\n",
        "    G.print_layers(); D.print_layers()\n",
        "    sched = training_schedule(cur_nimg=total_kimg*1000, training_set=training_set, tick_size=tick_size, **sched_args)\n",
        "    grid_latents = np.random.randn(np.prod(grid_size), *G.input_shape[1:])\n",
        "    grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch_gpu)\n",
        "    grid=grid_fakes\n",
        "    if ganformer:\n",
        "      grid=grid_fakes[0]\n",
        "    misc.save_image_grid(grid, dnnlib.make_run_dir_path('fakes_init.png'), drange=drange_net, grid_size=grid_size)\n",
        "\n",
        "    # Setup training inputs.\n",
        "    print('Building TensorFlow graph...')\n",
        "    with tf.name_scope('Inputs'), tf.device('/cpu:0'):\n",
        "        lod_in               = tf.placeholder(tf.float32, name='lod_in', shape=[])\n",
        "        lrate_in             = tf.placeholder(tf.float32, name='lrate_in', shape=[])\n",
        "        minibatch_size_in    = tf.placeholder(tf.int32, name='minibatch_size_in', shape=[])\n",
        "        minibatch_gpu_in     = tf.placeholder(tf.int32, name='minibatch_gpu_in', shape=[])\n",
        "        minibatch_multiplier = minibatch_size_in // (minibatch_gpu_in * num_gpus)\n",
        "        Gs_beta              = 0.5 ** tf.div(tf.cast(minibatch_size_in, tf.float32), G_smoothing_kimg * 1000.0) if G_smoothing_kimg > 0.0 else 0.0\n",
        "\n",
        "    # Setup optimizers.\n",
        "    G_opt_args = dict(G_opt_args)\n",
        "    D_opt_args = dict(D_opt_args)\n",
        "    for args, reg_interval in [(G_opt_args, G_reg_interval), (D_opt_args, D_reg_interval)]:\n",
        "        args['minibatch_multiplier'] = minibatch_multiplier\n",
        "        args['learning_rate'] = lrate_in\n",
        "        if lazy_regularization:\n",
        "            mb_ratio = reg_interval / (reg_interval + 1)\n",
        "            args['learning_rate'] *= mb_ratio\n",
        "            if 'beta1' in args: args['beta1'] **= mb_ratio\n",
        "            if 'beta2' in args: args['beta2'] **= mb_ratio\n",
        "    G_opt = tflib.Optimizer(name='TrainG', **G_opt_args)\n",
        "    D_opt = tflib.Optimizer(name='TrainD', **D_opt_args)\n",
        "    G_reg_opt = tflib.Optimizer(name='RegG', share=G_opt, **G_opt_args)\n",
        "    D_reg_opt = tflib.Optimizer(name='RegD', share=D_opt, **D_opt_args)\n",
        "\n",
        "    # Build training graph for each GPU.\n",
        "    data_fetch_ops = []\n",
        "    for gpu in range(num_gpus):\n",
        "        with tf.name_scope('GPU%d' % gpu), tf.device('/gpu:%d' % gpu):\n",
        "\n",
        "            # Create GPU-specific shadow copies of G and D.\n",
        "            G_gpu = G if gpu == 0 else G.clone(G.name + '_shadow')\n",
        "            D_gpu = D if gpu == 0 else D.clone(D.name + '_shadow')\n",
        "\n",
        "            # Fetch training data via temporary variables.\n",
        "            with tf.name_scope('DataFetch'):\n",
        "                sched = training_schedule(cur_nimg=int(resume_kimg*1000), training_set=training_set,tick_size=tick_size, **sched_args)\n",
        "                reals_var = tf.Variable(name='reals', trainable=False, initial_value=tf.zeros([sched.minibatch_gpu] + training_set.shape))\n",
        "                labels_var = tf.Variable(name='labels', trainable=False, initial_value=tf.zeros([sched.minibatch_gpu, training_set.label_size]))\n",
        "                reals_write, labels_write = training_set.get_minibatch_tf()\n",
        "                reals_write, labels_write = process_reals(reals_write, labels_write, lod_in, mirror_augment, training_set.dynamic_range, drange_net)\n",
        "                reals_write = tf.concat([reals_write, reals_var[minibatch_gpu_in:]], axis=0)\n",
        "                labels_write = tf.concat([labels_write, labels_var[minibatch_gpu_in:]], axis=0)\n",
        "                data_fetch_ops += [tf.assign(reals_var, reals_write)]\n",
        "                data_fetch_ops += [tf.assign(labels_var, labels_write)]\n",
        "                reals_read = reals_var[:minibatch_gpu_in]\n",
        "                labels_read = labels_var[:minibatch_gpu_in]\n",
        "\n",
        "            # Evaluate loss functions.\n",
        "            lod_assign_ops = []\n",
        "            if 'lod' in G_gpu.vars: lod_assign_ops += [tf.assign(G_gpu.vars['lod'], lod_in)]\n",
        "            if 'lod' in D_gpu.vars: lod_assign_ops += [tf.assign(D_gpu.vars['lod'], lod_in)]\n",
        "            with tf.control_dependencies(lod_assign_ops):\n",
        "                with tf.name_scope('G_loss'):\n",
        "                    G_loss, G_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=G_opt, training_set=training_set, minibatch_size=minibatch_gpu_in, **G_loss_args)\n",
        "                with tf.name_scope('D_loss'):\n",
        "                    D_loss, D_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=D_opt, training_set=training_set, minibatch_size=minibatch_gpu_in, reals=reals_read, labels=labels_read, **D_loss_args)\n",
        "\n",
        "            # Register gradients.\n",
        "            if not lazy_regularization:\n",
        "                if G_reg is not None: G_loss += G_reg\n",
        "                if D_reg is not None: D_loss += D_reg\n",
        "            else:\n",
        "                if G_reg is not None: G_reg_opt.register_gradients(tf.reduce_mean(G_reg * G_reg_interval), G_gpu.trainables)\n",
        "                if D_reg is not None: D_reg_opt.register_gradients(tf.reduce_mean(D_reg * D_reg_interval), D_gpu.trainables)\n",
        "            G_opt.register_gradients(tf.reduce_mean(G_loss), G_gpu.trainables)\n",
        "            D_opt.register_gradients(tf.reduce_mean(D_loss), D_gpu.trainables)\n",
        "\n",
        "    # Setup training ops.\n",
        "    data_fetch_op = tf.group(*data_fetch_ops)\n",
        "    G_train_op = G_opt.apply_updates()\n",
        "    D_train_op = D_opt.apply_updates()\n",
        "    G_reg_op = G_reg_opt.apply_updates(allow_no_op=True)\n",
        "    D_reg_op = D_reg_opt.apply_updates(allow_no_op=True)\n",
        "    Gs_update_op = Gs.setup_as_moving_average_of(G, beta=Gs_beta)\n",
        "\n",
        "    # Finalize graph.\n",
        "    with tf.device('/gpu:0'):\n",
        "        try:\n",
        "            peak_gpu_mem_op = tf.contrib.memory_stats.MaxBytesInUse()\n",
        "        except tf.errors.NotFoundError:\n",
        "            peak_gpu_mem_op = tf.constant(0)\n",
        "    tflib.init_uninitialized_vars()\n",
        "\n",
        "    print('Initializing logs...')\n",
        "    summary_log = tf.summary.FileWriter(dnnlib.make_run_dir_path())\n",
        "    if save_tf_graph:\n",
        "        summary_log.add_graph(tf.get_default_graph())\n",
        "    if save_weight_histograms:\n",
        "        G.setup_weight_histograms(); D.setup_weight_histograms()\n",
        "    metrics = metric_base.MetricGroup(metric_arg_list)\n",
        "\n",
        "    print('Training for %d kimg...\\n' % total_kimg)\n",
        "    dnnlib.RunContext.get().update('', cur_epoch=resume_kimg, max_epoch=total_kimg)\n",
        "    maintenance_time = dnnlib.RunContext.get().get_last_update_interval()\n",
        "    cur_nimg = int(resume_kimg * 1000)\n",
        "    cur_tick = -1\n",
        "    tick_start_nimg = cur_nimg\n",
        "    prev_lod = -1.0\n",
        "    running_mb_counter = 0\n",
        "    while cur_nimg < total_kimg * 1000:\n",
        "        if dnnlib.RunContext.get().should_stop(): break\n",
        "\n",
        "        # Choose training parameters and configure training ops.\n",
        "        sched = training_schedule(cur_nimg=cur_nimg, training_set=training_set,tick_size=tick_size, **sched_args)\n",
        "        assert sched.minibatch_size % (sched.minibatch_gpu * num_gpus) == 0\n",
        "        training_set.configure(sched.minibatch_gpu, sched.lod)\n",
        "        if reset_opt_for_new_lod:\n",
        "            if np.floor(sched.lod) != np.floor(prev_lod) or np.ceil(sched.lod) != np.ceil(prev_lod):\n",
        "                G_opt.reset_optimizer_state(); D_opt.reset_optimizer_state()\n",
        "        prev_lod = sched.lod\n",
        "\n",
        "        # Run training ops.\n",
        "        feed_dict = {lod_in: sched.lod, lrate_in: sched.G_lrate, minibatch_size_in: sched.minibatch_size, minibatch_gpu_in: sched.minibatch_gpu}\n",
        "        for _repeat in range(minibatch_repeats):\n",
        "            rounds = range(0, sched.minibatch_size, sched.minibatch_gpu * num_gpus)\n",
        "            run_G_reg = (lazy_regularization and running_mb_counter % G_reg_interval == 0)\n",
        "            run_D_reg = (lazy_regularization and running_mb_counter % D_reg_interval == 0)\n",
        "            cur_nimg += sched.minibatch_size\n",
        "            running_mb_counter += 1\n",
        "\n",
        "            # Fast path without gradient accumulation.\n",
        "            if len(rounds) == 1:\n",
        "                tflib.run([G_train_op, data_fetch_op], feed_dict)\n",
        "                if run_G_reg:\n",
        "                    tflib.run(G_reg_op, feed_dict)\n",
        "                tflib.run([D_train_op, Gs_update_op], feed_dict)\n",
        "                if run_D_reg:\n",
        "                    tflib.run(D_reg_op, feed_dict)\n",
        "\n",
        "            # Slow path with gradient accumulation.\n",
        "            else:\n",
        "                for _round in rounds:\n",
        "                    tflib.run(G_train_op, feed_dict)\n",
        "                if run_G_reg:\n",
        "                    for _round in rounds:\n",
        "                        tflib.run(G_reg_op, feed_dict)\n",
        "                tflib.run(Gs_update_op, feed_dict)\n",
        "                for _round in rounds:\n",
        "                    tflib.run(data_fetch_op, feed_dict)\n",
        "                    tflib.run(D_train_op, feed_dict)\n",
        "                if run_D_reg:\n",
        "                    for _round in rounds:\n",
        "                        tflib.run(D_reg_op, feed_dict)\n",
        "\n",
        "        # Perform maintenance tasks once per tick.\n",
        "        done = (cur_nimg >= total_kimg * 1000)\n",
        "        if cur_tick < 0 or cur_nimg >= tick_start_nimg + sched.tick_kimg * 1000 or done:\n",
        "            cur_tick += 1\n",
        "            tick_kimg = (cur_nimg - tick_start_nimg) / 1000.0\n",
        "            tick_start_nimg = cur_nimg\n",
        "            tick_time = dnnlib.RunContext.get().get_time_since_last_update()\n",
        "            total_time = dnnlib.RunContext.get().get_time_since_start() + resume_time\n",
        "\n",
        "            # Report progress.\n",
        "            print('tick %-5d kimg %-8.1f lod %-5.2f minibatch %-4d time %-12s sec/tick %-7.1f sec/kimg %-7.2f maintenance %-6.1f gpumem %.1f' % (\n",
        "                autosummary('Progress/tick', cur_tick),\n",
        "                autosummary('Progress/kimg', cur_nimg / 1000.0),\n",
        "                autosummary('Progress/lod', sched.lod),\n",
        "                autosummary('Progress/minibatch', sched.minibatch_size),\n",
        "                dnnlib.util.format_time(autosummary('Timing/total_sec', total_time)),\n",
        "                autosummary('Timing/sec_per_tick', tick_time),\n",
        "                autosummary('Timing/sec_per_kimg', tick_time / tick_kimg),\n",
        "                autosummary('Timing/maintenance_sec', maintenance_time),\n",
        "                autosummary('Resources/peak_gpu_mem_gb', peak_gpu_mem_op.eval() / 2**30)))\n",
        "            autosummary('Timing/total_hours', total_time / (60.0 * 60.0))\n",
        "            autosummary('Timing/total_days', total_time / (24.0 * 60.0 * 60.0))\n",
        "\n",
        "            # Save snapshots.\n",
        "            if image_snapshot_ticks is not None and (cur_tick % image_snapshot_ticks == 0 or done):\n",
        "                grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch_gpu)\n",
        "                grid=grid_fakes\n",
        "                if ganformer:\n",
        "                  grid=grid_fakes[0]\n",
        "                  \n",
        "                misc.save_image_grid(grid, dnnlib.make_run_dir_path('fakes%06d.png') % (cur_nimg // 1000), drange=drange_net, grid_size=grid_size)\n",
        "            if network_snapshot_ticks is not None and (cur_tick % network_snapshot_ticks == 0 or done):\n",
        "                pkl = dnnlib.make_run_dir_path('network-snapshot-%06d.pkl') % (cur_nimg // 1000)\n",
        "                misc.save_pkl((G, D, Gs), pkl)\n",
        "            # if network_snapshot_ticks is not None and done:\n",
        "                # metrics.run(pkl, run_dir=dnnlib.make_run_dir_path(), data_dir=dnnlib.convert_path(data_dir), num_gpus=num_gpus, tf_config=tf_config)\n",
        "\n",
        "            # Update summaries and RunContext.\n",
        "            metrics.update_autosummaries()\n",
        "            tflib.autosummary.save_summaries(summary_log, cur_nimg)\n",
        "            dnnlib.RunContext.get().update('%.2f' % sched.lod, cur_epoch=cur_nimg // 1000, max_epoch=total_kimg)\n",
        "            maintenance_time = dnnlib.RunContext.get().get_last_update_interval() - tick_time\n",
        "\n",
        "    # Save final snapshot.\n",
        "    misc.save_pkl((G, D, Gs), dnnlib.make_run_dir_path('network-final.pkl'))\n",
        "    metrics.run(dnnlib.make_run_dir_path('network-final.pkl'), run_dir=dnnlib.make_run_dir_path(), data_dir=dnnlib.convert_path(data_dir), num_gpus=num_gpus, tf_config=tf_config)\n",
        "    \n",
        "    # All done.\n",
        "    summary_log.close()\n",
        "    training_set.close()\n",
        "\n",
        "  #----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting training_loop.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-t7vA0nt71-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhfj6YBxwAdb",
        "outputId": "7ad0840c-c831-42d9-bbb3-a627c77574aa"
      },
      "source": [
        "%cd /content/GANFormer\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GANFormer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPU79iCLtAYq"
      },
      "source": [
        "ganformer=True\n",
        "duplex=True\n",
        "attention_discriminator=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgIfP3zmOGkY"
      },
      "source": [
        "dataset = 'custom'\n",
        "data_dir = '/content/datasets/'\n",
        "num_gpus = 1\n",
        "total_kimg = 96\n",
        "mirror_augment = True\n",
        "metrics = ['fid50k', 'is50k', 'pr50k3']\n",
        "gamma = None\n",
        "tick_size=2\n",
        "result_dir = '/content/drive/MyDrive/GAN/'\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pufC7hNgpA_Y",
        "outputId": "6fdb03f4-b2a7-46d9-a354-9fc4531da395"
      },
      "source": [
        "# setup\n",
        "import argparse\n",
        "import copy\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import dnnlib\n",
        "from dnnlib import EasyDict\n",
        "\n",
        "from metrics.metric_defaults import metric_defaults\n",
        "\n",
        "\n",
        "train     = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n",
        "\n",
        "\n",
        "sched     = EasyDict()                                                     # Options for TrainingSchedule.\n",
        "grid      = EasyDict(size='8k', layout='random')                           # Options for setup_snapshot_image_grid().\n",
        "sc        = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n",
        "tf_config = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n",
        "\n",
        "\n",
        "if ganformer:\n",
        "  G = EasyDict(func_name='training.networks_GANFormer.G_GANformer', truncation_psi = 0.65, \n",
        "               architecture = 'resnet', latent_size = 32, \n",
        "               dlatent_size = 32, components_num = 16, \n",
        "               mapping_resnet = True, style = True, \n",
        "               fused_modconv = True, local_noise = True, \n",
        "               transformer = True, norm = 'layer', \n",
        "               integration = 'mul', kmeans = duplex, \n",
        "               kmeans_iters = 1, mapping_ltnt2ltnt = True, \n",
        "               use_pos = True, num_heads = 1, \n",
        "               pos_init = 'uniform', pos_directions_num = 2, \n",
        "               merge_layer = -1, start_res = 0, \n",
        "               end_res = 8, img2img = 0, \n",
        "               style_mixing = 0.9, component_mixing = 0.0, \n",
        "               component_dropout = 0.0)       # Options for generator network.\n",
        "\n",
        "  if attention_discriminator:\n",
        "    func_name='training.networks_GANFormer.D_GANformer'\n",
        "  else:\n",
        "    func_name='training.networks_GANFormer.D_Stylegan'\n",
        "    \n",
        "  D = EasyDict(func_name=func_name, latent_size = 32,\n",
        "               components_num = 16, mbstd_group_size = 4, \n",
        "               use_pos = True, num_heads = 1, \n",
        "               pos_init = 'uniform', pos_directions_num = 2, \n",
        "               start_res = 0, end_res = 8, img2img = 0)  # Options for discriminator network.\n",
        "  G_loss = EasyDict(func_name='training.loss.G_logistic_ns_pathreg')      # Options for generator loss.\n",
        "  D_loss = EasyDict(func_name='training.loss.D_logistic_r1')              # Options for discriminator loss.\n",
        "  # G_opt = EasyDict(beta1=0.9, beta2=0.999, epsilon=1e-3)                  # Options for generator optimizer.\n",
        "  # D_opt = EasyDict(beta1=0.9, beta2=0.999, epsilon=1e-3)                  # Options for discriminator optimizer.\n",
        "  G_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "  D_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "  desc = 'GANFormer'\n",
        "else:\n",
        "  G = EasyDict(func_name='training.networks_stylegan2.G_main')       # Options for generator network.\n",
        "  D = EasyDict(func_name='training.networks_stylegan2.D_stylegan2')  # Options for discriminator network.\n",
        "  G_loss = EasyDict(func_name='training.loss_stylegan2.G_logistic_ns_pathreg')      # Options for generator loss.\n",
        "  D_loss = EasyDict(func_name='training.loss_stylegan2.D_logistic_r1')              # Options for discriminator loss.\n",
        "  G_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "  D_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "  desc = 'stylegan2'\n",
        "\n",
        "\n",
        "\n",
        "train.data_dir = data_dir\n",
        "train.total_kimg = total_kimg\n",
        "train.mirror_augment = mirror_augment\n",
        "train.image_snapshot_ticks = train.network_snapshot_ticks = 1\n",
        "sched.G_lrate_base = sched.D_lrate_base = 0.002\n",
        "sched.minibatch_size_base = 32\n",
        "sched.minibatch_gpu_base = 4\n",
        "D_loss.gamma = 10\n",
        "metrics = [metric_defaults[x] for x in metrics]\n",
        "\n",
        "\n",
        "desc += '-' + dataset\n",
        "dataset_args = EasyDict(tfrecord_dir=dataset)\n",
        "\n",
        "assert num_gpus in [1, 2, 4, 8]\n",
        "sc.num_gpus = num_gpus\n",
        "desc += '-%dgpu' % num_gpus\n",
        "\n",
        "if gamma is not None:\n",
        "    D_loss.gamma = gamma\n",
        "\n",
        "sc.submit_target = dnnlib.SubmitTarget.LOCAL\n",
        "sc.local.do_not_copy_source_files = True\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "kwargs = EasyDict(train)\n",
        "kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n",
        "kwargs.update(dataset_args=dataset_args, sched_args=sched, grid_args=grid, metric_arg_list=metrics, tf_config=tf_config,tick_size=tick_size, ganformer=ganformer)\n",
        "kwargs.submit_config = copy.deepcopy(sc)\n",
        "kwargs.submit_config.run_dir_root = result_dir\n",
        "kwargs.submit_config.run_desc = desc\n",
        "dnnlib.submit_run(**kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local submit - run_dir: /content/drive/MyDrive/GAN/00003-stylegan2-custom-1gpu\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "WARNING: Entity <function TFRecordDataset.parse_tfrecord_tf at 0x7fb7d02c98c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "Dataset shape = [3, 64, 64]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "\n",
            "\u001b[1m\u001b[34mG                           Params    OutputShape       WeightShape     \u001b[0m\n",
            "---                         ---       ---               ---             \n",
            "\u001b[1mG_mapping/Dense0\u001b[0m            262656    (?, 512)          (512, 512)      \n",
            "\u001b[1mG_mapping/Dense1\u001b[0m            262656    (?, 512)          (512, 512)      \n",
            "\u001b[1mG_mapping/Dense2\u001b[0m            262656    (?, 512)          (512, 512)      \n",
            "\u001b[1mG_mapping/Dense3\u001b[0m            262656    (?, 512)          (512, 512)      \n",
            "\u001b[1mG_mapping/Dense4\u001b[0m            262656    (?, 512)          (512, 512)      \n",
            "\u001b[1mG_mapping/Dense5\u001b[0m            262656    (?, 512)          (512, 512)      \n",
            "\u001b[1mG_mapping/Dense6\u001b[0m            262656    (?, 512)          (512, 512)      \n",
            "\u001b[1mG_mapping/Dense7\u001b[0m            262656    (?, 512)          (512, 512)      \n",
            "\u001b[1mG_synthesis/4x4/Const\u001b[0m       8192      (?, 512, 4, 4)    (1, 512, 4, 4)  \n",
            "\u001b[1mG_synthesis/4x4/Conv\u001b[0m        2622465   (?, 512, 4, 4)    (3, 3, 512, 512)\n",
            "\u001b[1mG_synthesis/4x4/ToRGB\u001b[0m       264195    (?, 3, 4, 4)      (1, 1, 512, 3)  \n",
            "\u001b[1mG_synthesis/8x8/Conv0_up\u001b[0m    2622465   (?, 512, 8, 8)    (3, 3, 512, 512)\n",
            "\u001b[1mG_synthesis/8x8/Conv1\u001b[0m       2622465   (?, 512, 8, 8)    (3, 3, 512, 512)\n",
            "\u001b[1mG_synthesis/8x8/ToRGB\u001b[0m       264195    (?, 3, 8, 8)      (1, 1, 512, 3)  \n",
            "\u001b[1mG_synthesis/16x16/Conv0_up\u001b[0m  2622465   (?, 512, 16, 16)  (3, 3, 512, 512)\n",
            "\u001b[1mG_synthesis/16x16/Conv1\u001b[0m     2622465   (?, 512, 16, 16)  (3, 3, 512, 512)\n",
            "\u001b[1mG_synthesis/16x16/ToRGB\u001b[0m     264195    (?, 3, 16, 16)    (1, 1, 512, 3)  \n",
            "\u001b[1mG_synthesis/32x32/Conv0_up\u001b[0m  2622465   (?, 512, 32, 32)  (3, 3, 512, 512)\n",
            "\u001b[1mG_synthesis/32x32/Conv1\u001b[0m     2622465   (?, 512, 32, 32)  (3, 3, 512, 512)\n",
            "\u001b[1mG_synthesis/32x32/ToRGB\u001b[0m     264195    (?, 3, 32, 32)    (1, 1, 512, 3)  \n",
            "\u001b[1mG_synthesis/64x64/Conv0_up\u001b[0m  2622465   (?, 512, 64, 64)  (3, 3, 512, 512)\n",
            "\u001b[1mG_synthesis/64x64/Conv1\u001b[0m     2622465   (?, 512, 64, 64)  (3, 3, 512, 512)\n",
            "\u001b[1mG_synthesis/64x64/ToRGB\u001b[0m     264195    (?, 3, 64, 64)    (1, 1, 512, 3)  \n",
            "---                         ---       ---               ---             \n",
            "\u001b[1m\u001b[31mTotal                       27032600                                    \u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[34mD                 Params    OutputShape       WeightShape     \u001b[0m\n",
            "---               ---       ---               ---             \n",
            "\u001b[1m64x64/FromRGB\u001b[0m     2048      (?, 512, 64, 64)  (1, 1, 3, 512)  \n",
            "\u001b[1m64x64/Conv0\u001b[0m       2359808   (?, 512, 64, 64)  (3, 3, 512, 512)\n",
            "\u001b[1m64x64/Conv1_down\u001b[0m  2359808   (?, 512, 32, 32)  (3, 3, 512, 512)\n",
            "\u001b[1m64x64/Skip\u001b[0m        262144    (?, 512, 32, 32)  (1, 1, 512, 512)\n",
            "\u001b[1m32x32/Conv0\u001b[0m       2359808   (?, 512, 32, 32)  (3, 3, 512, 512)\n",
            "\u001b[1m32x32/Conv1_down\u001b[0m  2359808   (?, 512, 16, 16)  (3, 3, 512, 512)\n",
            "\u001b[1m32x32/Skip\u001b[0m        262144    (?, 512, 16, 16)  (1, 1, 512, 512)\n",
            "\u001b[1m16x16/Conv0\u001b[0m       2359808   (?, 512, 16, 16)  (3, 3, 512, 512)\n",
            "\u001b[1m16x16/Conv1_down\u001b[0m  2359808   (?, 512, 8, 8)    (3, 3, 512, 512)\n",
            "\u001b[1m16x16/Skip\u001b[0m        262144    (?, 512, 8, 8)    (1, 1, 512, 512)\n",
            "\u001b[1m8x8/Conv0\u001b[0m         2359808   (?, 512, 8, 8)    (3, 3, 512, 512)\n",
            "\u001b[1m8x8/Conv1_down\u001b[0m    2359808   (?, 512, 4, 4)    (3, 3, 512, 512)\n",
            "\u001b[1m8x8/Skip\u001b[0m          262144    (?, 512, 4, 4)    (1, 1, 512, 512)\n",
            "\u001b[1m4x4/Conv\u001b[0m          2364416   (?, 512, 4, 4)    (3, 3, 513, 512)\n",
            "\u001b[1m4x4/Dense0\u001b[0m        4194816   (?, 512)          (8192, 512)     \n",
            "\u001b[1mOutput/weight\u001b[0m     512       (512, 1)          (512, 1)        \n",
            "\u001b[1mOutput/bias\u001b[0m       1         (1,)              (1,)            \n",
            "---               ---       ---               ---             \n",
            "\u001b[1m\u001b[31mTotal             26488833                                    \u001b[0m\n",
            "\n",
            "Building TensorFlow graph...\n",
            "Initializing logs...\n",
            "Training for 96 kimg...\n",
            "\n",
            "tick 0     kimg 0.1      lod 0.00  minibatch 32   time 22s          sec/tick 21.8    sec/kimg 170.36  maintenance 0.0    gpumem 4.7\n",
            "tick 1     kimg 2.2      lod 0.00  minibatch 32   time 3m 49s       sec/tick 186.6   sec/kimg 91.12   maintenance 21.1   gpumem 4.7\n",
            "tick 2     kimg 4.2      lod 0.00  minibatch 32   time 7m 09s       sec/tick 186.4   sec/kimg 91.02   maintenance 12.9   gpumem 4.7\n",
            "tick 3     kimg 6.3      lod 0.00  minibatch 32   time 10m 28s      sec/tick 186.3   sec/kimg 90.96   maintenance 13.0   gpumem 4.7\n",
            "tick 4     kimg 8.3      lod 0.00  minibatch 32   time 13m 47s      sec/tick 186.3   sec/kimg 90.98   maintenance 13.0   gpumem 4.7\n",
            "tick 5     kimg 10.4     lod 0.00  minibatch 32   time 17m 07s      sec/tick 186.3   sec/kimg 90.99   maintenance 13.0   gpumem 4.7\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9d60c7dc1c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_dir_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/GANFormer/dnnlib/submission/submit.py\u001b[0m in \u001b[0;36msubmit_run\u001b[0;34m(submit_config, run_func_name, **run_func_kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mfarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_submit_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost_run_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0m_populate_run_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost_run_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost_run_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/GANFormer/dnnlib/submission/internal/local.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, submit_config, host_run_dir)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'- run_dir: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconvert_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/GANFormer/dnnlib/submission/submit.py\u001b[0m in \u001b[0;36mrun_wrapper\u001b[0;34m(submit_config)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mrun_func_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_func_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mrun_func_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_func_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dnnlib: Finished {0}() in {1}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_func_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GANFormer/training/training_loop.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(G_args, D_args, G_opt_args, D_opt_args, G_loss_args, D_loss_args, dataset_args, sched_args, grid_args, metric_arg_list, tf_config, data_dir, G_smoothing_kimg, minibatch_repeats, lazy_regularization, G_reg_interval, D_reg_interval, reset_opt_for_new_lod, total_kimg, mirror_augment, drange_net, image_snapshot_ticks, network_snapshot_ticks, save_tf_graph, save_weight_histograms, resume_pkl, resume_kimg, resume_time, resume_with_new_nets, tick_size, ganformer)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_D_reg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0m_round\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                         \u001b[0mtflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_reg_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Perform maintenance tasks once per tick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GANFormer/dnnlib/tflib/tfutil.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m\"\"\"Run the specified ops in the default session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0massert_tf_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA0LBnZrMcTy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}