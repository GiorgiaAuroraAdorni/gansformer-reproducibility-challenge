{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "# Reproducibility challenge: Ganformer\n",
        "##Stefano Carlo Lambertenghi, Felix Boelter, Giorgia Aurora Adorni\n",
        "###Training system\n",
        "\n",
        "USE: Allows for training of Stylegan2, Ganformer with simplex attention, Ganformer with duplex attention, \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF_Ce0gGyfaP",
        "outputId": "8bc6e822-b8cc-406f-f7c9-5ce66d9f9c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gansformer-reproducibility-challenge'...\n",
            "remote: Enumerating objects: 857, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 857 (delta 40), reused 79 (delta 32), pack-reused 766\u001b[K\n",
            "Receiving objects: 100% (857/857), 88.50 MiB | 13.85 MiB/s, done.\n",
            "Resolving deltas: 100% (487/487), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/GiorgiaAuroraAdorni/gansformer-reproducibility-challenge.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzDuIoMcqfBT",
        "outputId": "f0ea036e-b954-43a6-ae19-3148065c3325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Mounted at /content/drive\n",
            "Tensorflow version: 1.15.2\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-76bfea8a-02fb-0b9b-d3bf-9a69fdcea8fb)\n",
            "GPU Identified at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import gdown\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voSUPwv_rghw",
        "outputId": "1ac16d20-fac9-4449-c2e9-7d28704f58c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1e762iw6AiZ8CilrWc85Ok2wuaNTmiP09\n",
            "To: /content/TFRecords_FFHQ.zip\n",
            "100% 4.02G/4.02G [01:08<00:00, 58.5MB/s]\n",
            "Archive:  TFRecords_FFHQ.zip\n",
            "   creating: TFRecords_FFHQ/\n",
            "  inflating: __MACOSX/._TFRecords_FFHQ  \n",
            "  inflating: TFRecords_FFHQ/.DS_Store  \n",
            "  inflating: __MACOSX/TFRecords_FFHQ/._.DS_Store  \n",
            "   creating: TFRecords_FFHQ/custom/\n",
            "  inflating: __MACOSX/TFRecords_FFHQ/._custom  \n",
            "  inflating: TFRecords_FFHQ/custom/custom-r06.tfrecords  \n",
            "  inflating: __MACOSX/TFRecords_FFHQ/custom/._custom-r06.tfrecords  \n",
            "  inflating: TFRecords_FFHQ/custom/custom-r07.tfrecords  \n",
            "  inflating: __MACOSX/TFRecords_FFHQ/custom/._custom-r07.tfrecords  \n",
            "  inflating: TFRecords_FFHQ/custom/custom-r04.tfrecords  \n",
            "  inflating: __MACOSX/TFRecords_FFHQ/custom/._custom-r04.tfrecords  \n",
            "  inflating: TFRecords_FFHQ/custom/custom-r02.tfrecords  \n",
            "  inflating: __MACOSX/TFRecords_FFHQ/custom/._custom-r02.tfrecords  \n",
            "  inflating: TFRecords_FFHQ/custom/custom-r05.tfrecords  \n",
            "  inflating: __MACOSX/TFRecords_FFHQ/custom/._custom-r05.tfrecords  \n",
            "  inflating: TFRecords_FFHQ/custom/custom-r03.tfrecords  \n",
            "  inflating: __MACOSX/TFRecords_FFHQ/custom/._custom-r03.tfrecords  \n"
          ]
        }
      ],
      "source": [
        "#Download cartoonset/FFHQ dataset\n",
        "def download_tfrecords(dataset='Cartoon'):\n",
        "  '''\n",
        "  dataset: Which TFRecords to download Cartoon for the cartoon dataset, FFHQ for the FFHQ dataset\n",
        "  '''\n",
        "  %cd /content\n",
        "  if dataset == 'Cartoon':\n",
        "    !gdown https://drive.google.com/uc?id=1RVWqZdL4ezyskQTnQZC_ZakjL0MkpZVb\n",
        "    !unzip datasets.zip\n",
        "    !rm datasets.zip\n",
        "  elif dataset == 'FFHQ':\n",
        "    !gdown https://drive.google.com/uc?id=1e762iw6AiZ8CilrWc85Ok2wuaNTmiP09\n",
        "    !unzip TFRecords_FFHQ.zip\n",
        "    !rm -r __MACOSX\n",
        "    !rm TFRecords_FFHQ.zip\n",
        "tfrecords_dataset = 'FFHQ'\n",
        "download_tfrecords(dataset = tfrecords_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2snUQdVFhoiE"
      },
      "outputs": [],
      "source": [
        "# Manually import dataset\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "def reimport_dataset(dataset='Cartoon', resizing_size = 64, dataset_size = 10000):\n",
        "  '''\n",
        "  dataset: Cartoon (for the cartoon dataset) or FFHQ (for the FFHQ dataset)\n",
        "  resizing_size: Size of images when resizing. By default Cartoonset is resized to 64 and FFHQ is not resized and stays at 128.\n",
        "  dataset_size: Size of the dataset used in resizing. By default cartoonset has a length of 10000 and FFHQ has a size of 70000\n",
        "  '''\n",
        "  %cd /content\n",
        "  #Download training dataset\n",
        "  if dataset == 'Cartoon':\n",
        "    !gdown https://drive.google.com/uc?id=1WjlrpvRBrDghIfZ35Smrp9nzc9PekAoa\n",
        "    !tar -xvzf cartoonset10k.tgz\n",
        "    !rm  cartoonset10k.tgz\n",
        "    !rm cartoonset10k/*.csv\n",
        "    path = \"/content/cartoonset10k/\"\n",
        "  elif dataset == 'FFHQ':\n",
        "    !gdown https://drive.google.com/uc?id=1ldi--Ax4-EJKOLDtW7pVIXRdpRWIOXnM\n",
        "    !unzip FFHQ_thumbnails128_128.zip\n",
        "    !rm  FFHQ_thumbnails128_128.zip\n",
        "    !rm -r __MACOSX\n",
        "    path = \"/content/FFHQ_thumbnails128_128/FFHQ_imgs/\"\n",
        "\n",
        "  \n",
        "  from fastai.vision import verify_images\n",
        "  verify_images(path, delete=True)\n",
        "\n",
        "  !mkdir -p /content/custom/\n",
        "  files = os.listdir(path)\n",
        "\n",
        "\n",
        "  def resize(resize_shape, data_size):\n",
        "      files = os.listdir(path)\n",
        "      for i in tqdm(range(data_size)):\n",
        "        im = Image.open(path + files[i])\n",
        "        imResize = im.resize((resize_shape,resize_shape), Image.ANTIALIAS)\n",
        "        imResize.save(\"/content/custom/\" + files[i] , 'JPEG')\n",
        "  resize(resize_shape = resizing_size, data_size = dataset_size)\n",
        "  if dataset == 'Cartoon':\n",
        "    !rm -r /content/cartoonset10k/\n",
        "  elif dataset == 'FFHQ':\n",
        "    !rm -r /content/FFHQ_thumbnails128_128/\n",
        "\n",
        "  %cd /content/gansformer-reproducibility-challenge/src\n",
        "  !python dataset_tool.py create_from_images /content/datasets/custom /content/custom/\n",
        "  !rm -r /content/custom/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnjJYbV9W2Nl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xCY_BPMPsja"
      },
      "outputs": [],
      "source": [
        "#Import cityscapes dataset\n",
        "def import_cityscapes_dataset():\n",
        "  %cd /content\n",
        "  %mkdir data\n",
        "  %cd data\n",
        "  %mkdir cityscapes\n",
        "  gdown.download(\"https://drive.google.com/uc?id=1t9Qhxm0iHFd3k-xTYEbKosSx_DkyoLLJ\", \"/content/data/cityscapes/cityscapes.zip\",quiet=False)\n",
        "\n",
        "\n",
        "  def unzip(zip, dir):\n",
        "      with zipfile.ZipFile(zip) as zf:\n",
        "          for member in tqdm.tqdm(zf.infolist(), desc = \"Extracting \"):\n",
        "              try:\n",
        "                  zf.extract(member, dir)\n",
        "              except zipfile.error as e:\n",
        "                  pass\n",
        "\n",
        "\n",
        "  import os\n",
        "  import sys\n",
        "  import tqdm\n",
        "  import zipfile\n",
        "  unzip(\"/content/data/cityscapes/cityscapes.zip\", \"/content/data/cityscapes\")\n",
        "\n",
        "  !rm /content/data/cityscapes/cityscapes.zip\n",
        "\n",
        "  import glob\n",
        "  import os\n",
        "  for in_file in glob.glob('./cityscapes/*'):\n",
        "    in_file_name_1 = in_file[:in_file.find('.tfrecords')]\n",
        "    in_file_name_2 = in_file[len(in_file_name_1)+10:in_file.find('of')]\n",
        "    out_file = f'{in_file_name_1[:-2]}{str(in_file_name_2).zfill(2)}.tfrecords' \n",
        "    os.rename(in_file, out_file)\n",
        "    print(out_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEMscuV6qk9u",
        "outputId": "5d0fa67e-b2f5-4a7d-d2b7-df06ec5c34ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gansformer-reproducibility-challenge/src/training\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gansformer-reproducibility-challenge/src/training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSVoMnq1jNE-",
        "outputId": "29047783-f9dc-44c5-b1db-39e9d31ba907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting training_loop.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile training_loop.py\n",
        "\n",
        "# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n",
        "#\n",
        "# This work is made available under the Nvidia Source Code License-NC.\n",
        "# To view a copy of this license, visit\n",
        "# https://nvlabs.github.io/stylegan2/license.html\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from dnnlib.tflib.autosummary import autosummary\n",
        "\n",
        "from training import dataset\n",
        "from training import misc\n",
        "from metrics import metric_base\n",
        "from metrics.metric_defaults import metric_defaults\n",
        "import gc\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Just-in-time processing of training images before feeding them to the networks.\n",
        "\n",
        "def process_reals(x, labels, lod, mirror_augment, drange_data, drange_net):\n",
        "    with tf.name_scope('DynamicRange'):\n",
        "        x = tf.cast(x, tf.float32)\n",
        "        x = misc.adjust_dynamic_range(x, drange_data, drange_net)\n",
        "    if mirror_augment:\n",
        "        with tf.name_scope('MirrorAugment'):\n",
        "            x = tf.where(tf.random_uniform([tf.shape(x)[0]]) < 0.5, x, tf.reverse(x, [3]))\n",
        "    with tf.name_scope('FadeLOD'): # Smooth crossfade between consecutive levels-of-detail.\n",
        "        s = tf.shape(x)\n",
        "        y = tf.reshape(x, [-1, s[1], s[2]//2, 2, s[3]//2, 2])\n",
        "        y = tf.reduce_mean(y, axis=[3, 5], keepdims=True)\n",
        "        y = tf.tile(y, [1, 1, 1, 2, 1, 2])\n",
        "        y = tf.reshape(y, [-1, s[1], s[2], s[3]])\n",
        "        x = tflib.lerp(x, y, lod - tf.floor(lod))\n",
        "    with tf.name_scope('UpscaleLOD'): # Upscale to match the expected input/output size of the networks.\n",
        "        s = tf.shape(x)\n",
        "        factor = tf.cast(2 ** tf.floor(lod), tf.int32)\n",
        "        x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
        "        x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "        x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
        "    return x, labels\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Evaluate time-varying training parameters.\n",
        "\n",
        "def training_schedule(\n",
        "    cur_nimg,\n",
        "    training_set,\n",
        "    lod_initial_resolution  = None,     # Image resolution used at the beginning.\n",
        "    lod_training_kimg       = 600,      # Thousands of real images to show before doubling the resolution.\n",
        "    lod_transition_kimg     = 600,      # Thousands of real images to show when fading in new layers.\n",
        "    minibatch_size_base     = 16,       # Global minibatch size.\n",
        "    minibatch_size_dict     = {},       # Resolution-specific overrides.\n",
        "    minibatch_gpu_base      = 4,        # Number of samples processed at a time by one GPU.\n",
        "    minibatch_gpu_dict      = {},       # Resolution-specific overrides.\n",
        "    G_lrate_base            = 0.002,    # Learning rate for the generator.\n",
        "    G_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    D_lrate_base            = 0.002,    # Learning rate for the discriminator.\n",
        "    D_lrate_dict            = {},       # Resolution-specific overrides.\n",
        "    lrate_rampup_kimg       = 0,        # Duration of learning rate ramp-up.\n",
        "    tick_kimg_base          = 160,        # Default interval of progress snapshots.\n",
        "    tick_size          = 16): # Resolution-specific overrides.\n",
        "\n",
        "    # Initialize result dict.\n",
        "    s = dnnlib.EasyDict()\n",
        "    s.kimg = cur_nimg / 1000.0\n",
        "\n",
        "    # Training phase.\n",
        "    phase_dur = lod_training_kimg + lod_transition_kimg\n",
        "    phase_idx = int(np.floor(s.kimg / phase_dur)) if phase_dur > 0 else 0\n",
        "    phase_kimg = s.kimg - phase_idx * phase_dur\n",
        "    # Level-of-detail and resolution.\n",
        "    if lod_initial_resolution is None:\n",
        "        s.lod = 0.0\n",
        "    else:\n",
        "        s.lod = training_set.resolution_log2\n",
        "        s.lod -= np.floor(np.log2(lod_initial_resolution))\n",
        "        s.lod -= phase_idx\n",
        "        if lod_transition_kimg > 0:\n",
        "            s.lod -= max(phase_kimg - lod_training_kimg, 0.0) / lod_transition_kimg\n",
        "        s.lod = max(s.lod, 0.0)\n",
        "    s.resolution = 2 ** (training_set.resolution_log2 - int(np.floor(s.lod)))\n",
        "\n",
        "    # Minibatch size.\n",
        "    s.minibatch_size = minibatch_size_dict.get(s.resolution, minibatch_size_base)\n",
        "    s.minibatch_gpu = minibatch_gpu_dict.get(s.resolution, minibatch_gpu_base)\n",
        "\n",
        "    # Learning rate.\n",
        "    s.G_lrate = G_lrate_dict.get(s.resolution, G_lrate_base)\n",
        "    s.D_lrate = D_lrate_dict.get(s.resolution, D_lrate_base)\n",
        "    if lrate_rampup_kimg > 0:\n",
        "        rampup = min(s.kimg / lrate_rampup_kimg, 1.0)\n",
        "        s.G_lrate *= rampup\n",
        "        s.D_lrate *= rampup\n",
        "\n",
        "    # Other parameters.\n",
        "    s.tick_kimg = tick_size\n",
        "    return s\n",
        "\n",
        "\n",
        "\n",
        "def training_loop(\n",
        "    G_args                  = {},       # Options for generator network.\n",
        "    D_args                  = {},       # Options for discriminator network.\n",
        "    G_opt_args              = {},       # Options for generator optimizer.\n",
        "    D_opt_args              = {},       # Options for discriminator optimizer.\n",
        "    G_loss_args             = {},       # Options for generator loss.\n",
        "    D_loss_args             = {},       # Options for discriminator loss.\n",
        "    dataset_args            = {},       # Options for dataset.load_dataset().\n",
        "    sched_args              = {},       # Options for train.TrainingSchedule.\n",
        "    grid_args               = {},       # Options for train.setup_snapshot_image_grid().\n",
        "    metric_arg_list         = [],       # Options for MetricGroup.\n",
        "    metrics_10k_arg_list    = [],       # Options for MetricGroup_10k.\n",
        "    tf_config               = {},       # Options for tflib.init_tf().\n",
        "    data_dir                = None,     # Directory to load datasets from.\n",
        "    G_smoothing_kimg        = 10.0,     # Half-life of the running average of generator weights.\n",
        "    minibatch_repeats       = 4,        # Number of minibatches to run before adjusting training parameters.\n",
        "    lazy_regularization     = True,     # Perform regularization as a separate training step?\n",
        "    G_reg_interval          = 4,        # How often the perform regularization for G? Ignored if lazy_regularization=False.\n",
        "    D_reg_interval          = 16,       # How often the perform regularization for D? Ignored if lazy_regularization=False.\n",
        "    reset_opt_for_new_lod   = True,     # Reset optimizer internal state (e.g. Adam moments) when new layers are introduced?\n",
        "    total_kimg              = 25000,    # Total length of the training, measured in thousands of real images.\n",
        "    mirror_augment          = False,    # Enable mirror augment?\n",
        "    drange_net              = [-1,1],   # Dynamic range used when feeding image data to the networks.\n",
        "    image_snapshot_ticks    = 1,       # How often to save image snapshots? None = only save 'reals.png' and 'fakes-init.png'.\n",
        "    network_snapshot_ticks  = 1,       # How often to save network snapshots? None = only save 'networks-final.pkl'.\n",
        "    save_tf_graph           = False,    # Include full TensorFlow computation graph in the tfevents file?\n",
        "    save_weight_histograms  = False,    # Include weight histograms in the tfevents file?\n",
        "    resume_pkl              = None,     # Network pickle to resume training from, None = train from scratch.\n",
        "    resume_kimg             = 0,      # Assumed training progress at the beginning. Affects reporting and training schedule.\n",
        "    resume_time             = 0.0,      # Assumed wallclock time at the beginning. Affects reporting.\n",
        "    resume_with_new_nets    = False,\n",
        "    tick_size               = 16,\n",
        "    snapshot_saving_size    = 2,        # Number of snapshots to save\n",
        "    ganformer=True):   # Construct new networks according to G_args and D_args before resuming training?\n",
        "\n",
        "    # Initialize dnnlib and TensorFlow.\n",
        "    tflib.init_tf(tf_config)\n",
        "    num_gpus = dnnlib.submit_config.num_gpus\n",
        "\n",
        "    # Load training set.\n",
        "    training_set = dataset.load_dataset(data_dir=dnnlib.convert_path(data_dir), verbose=True, **dataset_args)\n",
        "    grid_size, grid_reals, grid_labels = misc.setup_snapshot_image_grid(training_set, **grid_args)\n",
        "    misc.save_image_grid(grid_reals, dnnlib.make_run_dir_path('reals.png'), drange=training_set.dynamic_range, grid_size=grid_size)\n",
        "\n",
        "    # Construct or load networks.\n",
        "    with tf.device('/gpu:0'):\n",
        "        if resume_pkl is None or resume_with_new_nets:\n",
        "            print('Constructing networks...')\n",
        "            G = tflib.Network('G', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **G_args)\n",
        "            D = tflib.Network('D', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **D_args)\n",
        "            Gs = G.clone('Gs')\n",
        "        if resume_pkl is not None:\n",
        "            print('Loading networks from \"%s\"...' % resume_pkl)\n",
        "            rG, rD, rGs = misc.load_pkl(resume_pkl)\n",
        "            if resume_with_new_nets: G.copy_vars_from(rG); D.copy_vars_from(rD); Gs.copy_vars_from(rGs)\n",
        "            else: G = rG; D = rD; Gs = rGs\n",
        "\n",
        "    # Print layers and generate initial image snapshot.\n",
        "    G.print_layers(); D.print_layers()\n",
        "    sched = training_schedule(cur_nimg=total_kimg*1000, training_set=training_set, tick_size=tick_size, **sched_args)\n",
        "    grid_latents = np.random.randn(np.prod(grid_size), *G.input_shape[1:])\n",
        "    grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch_gpu)\n",
        "    grid=grid_fakes\n",
        "    if ganformer:\n",
        "      grid=grid_fakes[0]\n",
        "    misc.save_image_grid(grid, dnnlib.make_run_dir_path('fakes_init.png'), drange=drange_net, grid_size=grid_size)\n",
        "\n",
        "    # Setup training inputs.\n",
        "    print('Building TensorFlow graph...')\n",
        "    with tf.name_scope('Inputs'), tf.device('/cpu:0'):\n",
        "        lod_in               = tf.placeholder(tf.float32, name='lod_in', shape=[])\n",
        "        lrate_in             = tf.placeholder(tf.float32, name='lrate_in', shape=[])\n",
        "        minibatch_size_in    = tf.placeholder(tf.int32, name='minibatch_size_in', shape=[])\n",
        "        minibatch_gpu_in     = tf.placeholder(tf.int32, name='minibatch_gpu_in', shape=[])\n",
        "        minibatch_multiplier = minibatch_size_in // (minibatch_gpu_in * num_gpus)\n",
        "        Gs_beta              = 0.5 ** tf.div(tf.cast(minibatch_size_in, tf.float32), G_smoothing_kimg * 1000.0) if G_smoothing_kimg > 0.0 else 0.0\n",
        "\n",
        "    # Setup optimizers.\n",
        "    G_opt_args = dict(G_opt_args)\n",
        "    D_opt_args = dict(D_opt_args)\n",
        "    for args, reg_interval in [(G_opt_args, G_reg_interval), (D_opt_args, D_reg_interval)]:\n",
        "        args['minibatch_multiplier'] = minibatch_multiplier\n",
        "        args['learning_rate'] = lrate_in\n",
        "        if lazy_regularization:\n",
        "            mb_ratio = reg_interval / (reg_interval + 1)\n",
        "            args['learning_rate'] *= mb_ratio\n",
        "            if 'beta1' in args: args['beta1'] **= mb_ratio\n",
        "            if 'beta2' in args: args['beta2'] **= mb_ratio\n",
        "    G_opt = tflib.Optimizer(name='TrainG', **G_opt_args)\n",
        "    D_opt = tflib.Optimizer(name='TrainD', **D_opt_args)\n",
        "    G_reg_opt = tflib.Optimizer(name='RegG', share=G_opt, **G_opt_args)\n",
        "    D_reg_opt = tflib.Optimizer(name='RegD', share=D_opt, **D_opt_args)\n",
        "\n",
        "    # Build training graph for each GPU.\n",
        "    data_fetch_ops = []\n",
        "    for gpu in range(num_gpus):\n",
        "        with tf.name_scope('GPU%d' % gpu), tf.device('/gpu:%d' % gpu):\n",
        "\n",
        "            # Create GPU-specific shadow copies of G and D.\n",
        "            G_gpu = G if gpu == 0 else G.clone(G.name + '_shadow')\n",
        "            D_gpu = D if gpu == 0 else D.clone(D.name + '_shadow')\n",
        "\n",
        "            # Fetch training data via temporary variables.\n",
        "            with tf.name_scope('DataFetch'):\n",
        "                sched = training_schedule(cur_nimg=int(resume_kimg*1000), training_set=training_set,tick_size=tick_size, **sched_args)\n",
        "                reals_var = tf.Variable(name='reals', trainable=False, initial_value=tf.zeros([sched.minibatch_gpu] + training_set.shape))\n",
        "                labels_var = tf.Variable(name='labels', trainable=False, initial_value=tf.zeros([sched.minibatch_gpu, training_set.label_size]))\n",
        "                reals_write, labels_write = training_set.get_minibatch_tf()\n",
        "                reals_write, labels_write = process_reals(reals_write, labels_write, lod_in, mirror_augment, training_set.dynamic_range, drange_net)\n",
        "                reals_write = tf.concat([reals_write, reals_var[minibatch_gpu_in:]], axis=0)\n",
        "                labels_write = tf.concat([labels_write, labels_var[minibatch_gpu_in:]], axis=0)\n",
        "                data_fetch_ops += [tf.assign(reals_var, reals_write)]\n",
        "                data_fetch_ops += [tf.assign(labels_var, labels_write)]\n",
        "                reals_read = reals_var[:minibatch_gpu_in]\n",
        "                labels_read = labels_var[:minibatch_gpu_in]\n",
        "\n",
        "            # Evaluate loss functions.\n",
        "            lod_assign_ops = []\n",
        "            if 'lod' in G_gpu.vars: lod_assign_ops += [tf.assign(G_gpu.vars['lod'], lod_in)]\n",
        "            if 'lod' in D_gpu.vars: lod_assign_ops += [tf.assign(D_gpu.vars['lod'], lod_in)]\n",
        "            with tf.control_dependencies(lod_assign_ops):\n",
        "                with tf.name_scope('G_loss'):\n",
        "                    G_loss, G_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=G_opt, training_set=training_set, minibatch_size=minibatch_gpu_in, **G_loss_args)\n",
        "                with tf.name_scope('D_loss'):\n",
        "                    D_loss, D_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=D_opt, training_set=training_set, minibatch_size=minibatch_gpu_in, reals=reals_read, labels=labels_read, **D_loss_args)\n",
        "\n",
        "            # Register gradients.\n",
        "            if not lazy_regularization:\n",
        "                if G_reg is not None: G_loss += G_reg\n",
        "                if D_reg is not None: D_loss += D_reg\n",
        "            else:\n",
        "                if G_reg is not None: G_reg_opt.register_gradients(tf.reduce_mean(G_reg * G_reg_interval), G_gpu.trainables)\n",
        "                if D_reg is not None: D_reg_opt.register_gradients(tf.reduce_mean(D_reg * D_reg_interval), D_gpu.trainables)\n",
        "            G_opt.register_gradients(tf.reduce_mean(G_loss), G_gpu.trainables)\n",
        "            D_opt.register_gradients(tf.reduce_mean(D_loss), D_gpu.trainables)\n",
        "\n",
        "    # Setup training ops.\n",
        "    data_fetch_op = tf.group(*data_fetch_ops)\n",
        "    G_train_op = G_opt.apply_updates()\n",
        "    D_train_op = D_opt.apply_updates()\n",
        "    G_reg_op = G_reg_opt.apply_updates(allow_no_op=True)\n",
        "    D_reg_op = D_reg_opt.apply_updates(allow_no_op=True)\n",
        "    Gs_update_op = Gs.setup_as_moving_average_of(G, beta=Gs_beta)\n",
        "\n",
        "    # Finalize graph.\n",
        "    with tf.device('/gpu:0'):\n",
        "        try:\n",
        "            peak_gpu_mem_op = tf.contrib.memory_stats.MaxBytesInUse()\n",
        "        except tf.errors.NotFoundError:\n",
        "            peak_gpu_mem_op = tf.constant(0)\n",
        "    tflib.init_uninitialized_vars()\n",
        "\n",
        "    print('Initializing logs...')\n",
        "    summary_log = tf.summary.FileWriter(dnnlib.make_run_dir_path())\n",
        "    if save_tf_graph:\n",
        "        summary_log.add_graph(tf.get_default_graph())\n",
        "    if save_weight_histograms:\n",
        "        G.setup_weight_histograms(); D.setup_weight_histograms()\n",
        "    metrics = metric_base.MetricGroup(metric_arg_list)\n",
        "    metrics_10k = metric_base.MetricGroup(metrics_10k_arg_list)\n",
        "\n",
        "    print('Training for %d kimg...\\n' % total_kimg)\n",
        "    dnnlib.RunContext.get().update('', cur_epoch=resume_kimg, max_epoch=total_kimg)\n",
        "    maintenance_time = dnnlib.RunContext.get().get_last_update_interval()\n",
        "    cur_nimg = int(resume_kimg * 1000)\n",
        "    cur_tick = -1\n",
        "    tick_start_nimg = cur_nimg\n",
        "    prev_lod = -1.0\n",
        "    running_mb_counter = 0\n",
        "    while cur_nimg < total_kimg * 1000:\n",
        "        if dnnlib.RunContext.get().should_stop(): break\n",
        "\n",
        "        # Choose training parameters and configure training ops.\n",
        "        sched = training_schedule(cur_nimg=cur_nimg, training_set=training_set,tick_size=tick_size, **sched_args)\n",
        "        assert sched.minibatch_size % (sched.minibatch_gpu * num_gpus) == 0\n",
        "        training_set.configure(sched.minibatch_gpu, sched.lod)\n",
        "        if reset_opt_for_new_lod:\n",
        "            if np.floor(sched.lod) != np.floor(prev_lod) or np.ceil(sched.lod) != np.ceil(prev_lod):\n",
        "                G_opt.reset_optimizer_state(); D_opt.reset_optimizer_state()\n",
        "        prev_lod = sched.lod\n",
        "\n",
        "        # Run training ops.\n",
        "        feed_dict = {lod_in: sched.lod, lrate_in: sched.G_lrate, minibatch_size_in: sched.minibatch_size, minibatch_gpu_in: sched.minibatch_gpu}\n",
        "        for _repeat in range(minibatch_repeats):\n",
        "            rounds = range(0, sched.minibatch_size, sched.minibatch_gpu * num_gpus)\n",
        "            run_G_reg = (lazy_regularization and running_mb_counter % G_reg_interval == 0)\n",
        "            run_D_reg = (lazy_regularization and running_mb_counter % D_reg_interval == 0)\n",
        "            cur_nimg += sched.minibatch_size\n",
        "            running_mb_counter += 1\n",
        "\n",
        "            # Fast path without gradient accumulation.\n",
        "            if len(rounds) == 1:\n",
        "                tflib.run([G_train_op, data_fetch_op], feed_dict)\n",
        "                if run_G_reg:\n",
        "                    tflib.run(G_reg_op, feed_dict)\n",
        "                tflib.run([D_train_op, Gs_update_op], feed_dict)\n",
        "                if run_D_reg:\n",
        "                    tflib.run(D_reg_op, feed_dict)\n",
        "\n",
        "            # Slow path with gradient accumulation.\n",
        "            else:\n",
        "                for _round in rounds:\n",
        "                    tflib.run(G_train_op, feed_dict)\n",
        "                if run_G_reg:\n",
        "                    for _round in rounds:\n",
        "                        tflib.run(G_reg_op, feed_dict)\n",
        "                tflib.run(Gs_update_op, feed_dict)\n",
        "                for _round in rounds:\n",
        "                    tflib.run(data_fetch_op, feed_dict)\n",
        "                    tflib.run(D_train_op, feed_dict)\n",
        "                if run_D_reg:\n",
        "                    for _round in rounds:\n",
        "                        tflib.run(D_reg_op, feed_dict)\n",
        "\n",
        "        # Perform maintenance tasks once per tick.\n",
        "        done = (cur_nimg >= total_kimg * 1000)\n",
        "        if cur_tick < 0 or cur_nimg >= tick_start_nimg + sched.tick_kimg * 1000 or done:\n",
        "            cur_tick += 1\n",
        "            tick_kimg = (cur_nimg - tick_start_nimg) / 1000.0\n",
        "            tick_start_nimg = cur_nimg\n",
        "            tick_time = dnnlib.RunContext.get().get_time_since_last_update()\n",
        "            total_time = dnnlib.RunContext.get().get_time_since_start() + resume_time\n",
        "\n",
        "            # Report progress.\n",
        "            print('tick %-5d kimg %-8.1f lod %-5.2f minibatch %-4d time %-12s sec/tick %-7.1f sec/kimg %-7.2f maintenance %-6.1f gpumem %.1f' % (\n",
        "                autosummary('Progress/tick', cur_tick),\n",
        "                autosummary('Progress/kimg', cur_nimg / 1000.0),\n",
        "                autosummary('Progress/lod', sched.lod),\n",
        "                autosummary('Progress/minibatch', sched.minibatch_size),\n",
        "                dnnlib.util.format_time(autosummary('Timing/total_sec', total_time)),\n",
        "                autosummary('Timing/sec_per_tick', tick_time),\n",
        "                autosummary('Timing/sec_per_kimg', tick_time / tick_kimg),\n",
        "                autosummary('Timing/maintenance_sec', maintenance_time),\n",
        "                autosummary('Resources/peak_gpu_mem_gb', peak_gpu_mem_op.eval() / 2**30)))\n",
        "            autosummary('Timing/total_hours', total_time / (60.0 * 60.0))\n",
        "            autosummary('Timing/total_days', total_time / (24.0 * 60.0 * 60.0))\n",
        "\n",
        "            # Save snapshots.\n",
        "            if image_snapshot_ticks is not None and (cur_tick % image_snapshot_ticks == 0 or done):\n",
        "                grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch_gpu)\n",
        "                grid=grid_fakes\n",
        "                if ganformer:\n",
        "                  grid=grid_fakes[0]\n",
        "                misc.save_image_grid(grid, dnnlib.make_run_dir_path('fakes%06d.png') % (cur_nimg // 1000), drange=drange_net, grid_size=grid_size)\n",
        "            if network_snapshot_ticks is not None and (cur_tick % network_snapshot_ticks == 0 or done):\n",
        "                pkl = dnnlib.make_run_dir_path('network-snapshot-%06d.pkl') % (cur_nimg // 1000)\n",
        "                misc.save_pkl((G, D, Gs), pkl)\n",
        "                metrics_10k.run(dnnlib.make_run_dir_path(('network-snapshot-%06d.pkl')% (cur_nimg // 1000)), run_dir=dnnlib.make_run_dir_path(), data_dir=dnnlib.convert_path(data_dir), num_gpus=num_gpus, tf_config=tf_config, ganformer=ganformer)\n",
        "                gc.collect(generation=2)\n",
        "            if snapshot_saving_size > 0:\n",
        "              files_to_remove = sorted(glob.glob(dnnlib.make_run_dir_path(\"network*.pkl\")))[:-snapshot_saving_size]\n",
        "              for f in files_to_remove:\n",
        "                os.remove(f)\n",
        "            # Update summaries and RunContext.\n",
        "            metrics.update_autosummaries()\n",
        "            tflib.autosummary.save_summaries(summary_log, cur_nimg)\n",
        "            dnnlib.RunContext.get().update('%.2f' % sched.lod, cur_epoch=cur_nimg // 1000, max_epoch=total_kimg)\n",
        "            maintenance_time = dnnlib.RunContext.get().get_last_update_interval() - tick_time\n",
        "\n",
        "    # Save final snapshot.\n",
        "    misc.save_pkl((G, D, Gs), dnnlib.make_run_dir_path('network-final.pkl'))\n",
        "    metrics.run(dnnlib.make_run_dir_path('network-final.pkl'), run_dir=dnnlib.make_run_dir_path(), data_dir=dnnlib.convert_path(data_dir), num_gpus=num_gpus, tf_config=tf_config, ganformer=ganformer)\n",
        "    # All done.\n",
        "    summary_log.close()\n",
        "    training_set.close()\n",
        "\n",
        "  #----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhfj6YBxwAdb",
        "outputId": "6a167025-a1ee-4f89-ec6b-dc1c2aa6ad02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gansformer-reproducibility-challenge/src\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPU79iCLtAYq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgIfP3zmOGkY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pufC7hNgpA_Y",
        "outputId": "39d9186f-114a-4a42-f5d9-8d47ce52c6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_training.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile run_training.py\n",
        "# setup\n",
        "import argparse\n",
        "import copy\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import dnnlib\n",
        "from dnnlib import EasyDict\n",
        "import numpy as np\n",
        "from metrics.metric_defaults import metric_defaults\n",
        "\n",
        "\n",
        "ganformer=True\n",
        "duplex=False\n",
        "attention_discriminator=False\n",
        "tfrecords_dataset = 'FFHQ'\n",
        "img_resolution = 64 if tfrecords_dataset == 'Cartoon' else 128 #Resolution of the Image default 64 for Cartoon 128 for FFHQ\n",
        "base_2_log = int(np.log2(img_resolution))\n",
        "dataset = 'custom'\n",
        "data_dir = '/content/datasets/' if tfrecords_dataset == 'Cartoon' else '/content/TFRecords_FFHQ/'\n",
        "# data_dir = '/content/datasets/'\n",
        "num_gpus = 1\n",
        "total_kimg = 300\n",
        "mirror_augment = True\n",
        "metrics = ['fid50k', 'is50k','pr50k3'] #' \n",
        "metrics_10k = ['fid10k']\n",
        "gamma = None\n",
        "tick_size=16\n",
        "result_dir = '/content/drive/MyDrive/model'\n",
        "if ganformer:\n",
        "    result_dir = '/content/drive/MyDrive/GANFORMER_Duplex/' if duplex else '/content/drive/MyDrive/GANFORMER_Simplex/'\n",
        "else:\n",
        "    result_dir = '/content/drive/MyDrive/STYLEGAN2/'\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "train     = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n",
        "sched     = EasyDict()                                                     # Options for TrainingSchedule.\n",
        "grid      = EasyDict(size='1080p', layout='random')                           # Options for setup_snapshot_image_grid().\n",
        "sc        = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n",
        "tf_config = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n",
        "\n",
        "\n",
        "if ganformer:\n",
        "  G = EasyDict(func_name='training.networks_GANFormer.G_GANformer', truncation_psi = 0.65, \n",
        "               architecture = 'resnet', latent_size = 32, \n",
        "               dlatent_size = 32, components_num = 16, \n",
        "               mapping_resnet = True, style = True, \n",
        "               fused_modconv = True, local_noise = True, \n",
        "               transformer = True, norm = 'layer', \n",
        "               integration = 'mul', kmeans = duplex, \n",
        "               kmeans_iters = 1, mapping_ltnt2ltnt = True, \n",
        "               use_pos = True, num_heads = 2, \n",
        "               pos_init = 'uniform', pos_directions_num = 2, \n",
        "               merge_layer = -1, start_res = 0, \n",
        "               end_res = base_2_log, img2img = 0, \n",
        "               style_mixing = 0.9, component_mixing = 0.0, \n",
        "               component_dropout = 0.0)       # Options for generator network.\n",
        "\n",
        "  if attention_discriminator:\n",
        "    func_name='training.networks_GANFormer.D_GANformer'\n",
        "  else:\n",
        "    func_name='training.networks_GANFormer.D_Stylegan'\n",
        "    \n",
        "  D = EasyDict(func_name=func_name, latent_size = 32,\n",
        "               components_num = 16, mbstd_group_size = 4, \n",
        "               use_pos = True, num_heads = 2, \n",
        "               pos_init = 'uniform', pos_directions_num = 2, \n",
        "               start_res = 0, end_res = base_2_log, img2img = 0)  # Options for discriminator network.\n",
        "  G_loss = EasyDict(func_name='training.loss.G_logistic_ns_pathreg')      # Options for generator loss.\n",
        "  D_loss = EasyDict(func_name='training.loss.D_logistic_r1')              # Options for discriminator loss.\n",
        "  # G_opt = EasyDict(beta1=0.9, beta2=0.999, epsilon=1e-3)                  # Options for generator optimizer.\n",
        "  # D_opt = EasyDict(beta1=0.9, beta2=0.999, epsilon=1e-3)                  # Options for discriminator optimizer.\n",
        "  G_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "  D_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "  desc = 'GANFormer'\n",
        "else:\n",
        "  G = EasyDict(func_name='training.networks_stylegan2.G_main')       # Options for generator network.\n",
        "  D = EasyDict(func_name='training.networks_stylegan2.D_stylegan2')  # Options for discriminator network.\n",
        "  G_loss = EasyDict(func_name='training.loss_stylegan2.G_logistic_ns_pathreg')      # Options for generator loss.\n",
        "  D_loss = EasyDict(func_name='training.loss_stylegan2.D_logistic_r1')              # Options for discriminator loss.\n",
        "  G_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "  D_opt = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "  desc = 'stylegan2'\n",
        "\n",
        "\n",
        "\n",
        "train.data_dir = data_dir\n",
        "train.total_kimg = total_kimg\n",
        "train.mirror_augment = mirror_augment\n",
        "train.image_snapshot_ticks = train.network_snapshot_ticks = 1\n",
        "sched.G_lrate_base = sched.D_lrate_base = 0.002\n",
        "sched.minibatch_size_base = 24\n",
        "sched.minibatch_gpu_base = 12\n",
        "D_loss.gamma = 10\n",
        "metrics = [metric_defaults[x] for x in metrics]\n",
        "metrics_10k = [metric_defaults[x] for x in metrics_10k]\n",
        "\n",
        "\n",
        "desc += '-' + dataset\n",
        "dataset_args = EasyDict(tfrecord_dir=dataset, resolution=img_resolution)\n",
        "\n",
        "assert num_gpus in [1, 2, 4, 8]\n",
        "sc.num_gpus = num_gpus\n",
        "desc += '-%dgpu' % num_gpus\n",
        "\n",
        "if gamma is not None:\n",
        "    D_loss.gamma = gamma\n",
        "\n",
        "sc.submit_target = dnnlib.SubmitTarget.LOCAL\n",
        "sc.local.do_not_copy_source_files = True\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "kwargs = EasyDict(train)\n",
        "kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n",
        "kwargs.update(dataset_args=dataset_args, sched_args=sched, grid_args=grid, metric_arg_list=metrics, metrics_10k_arg_list=metrics_10k, tf_config=tf_config,tick_size=tick_size, ganformer=ganformer,resume_pkl=\"/content/drive/MyDrive/GAN/network-snapshot-000300.pkl\",resume_kimg =300)\n",
        "kwargs.submit_config = copy.deepcopy(sc)\n",
        "kwargs.submit_config.run_dir_root = result_dir\n",
        "kwargs.submit_config.run_desc = desc\n",
        "dnnlib.submit_run(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PwzV3TjcM36K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd2aac4-fe29-4b5d-a254-252edc194b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local submit - run_dir: /content/drive/MyDrive/STYLEGAN2/00001-stylegan2-custom-1gpu\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55c9340a6000 @  0x7fa43f5fe001 0x7fa43c0e254f 0x7fa43c132b58 0x7fa43c136b17 0x7fa43c1d5203 0x55c92c3f8424 0x55c92c3f8120 0x55c92c46cb80 0x55c92c46766e 0x55c92c3fa36c 0x55c92c43b7b9 0x55c92c4386d4 0x55c92c3fa571 0x55c92c469633 0x55c92c46702f 0x55c92c338e2b 0x55c92c469633 0x55c92c46702f 0x55c92c338e2b 0x55c92c469633 0x55c92c3f99da 0x55c92c467eae 0x55c92c3f99da 0x55c92c468108 0x55c92c46702f 0x55c92c338e2b 0x55c92c469633 0x55c92c46702f 0x55c92c466d43 0x55c92c531302 0x55c92c53167d\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55ca340a6000 @  0x7fa43f5fc1e7 0x7fa43c0e246e 0x7fa43c132c7b 0x7fa43c13335f 0x7fa43c1d5103 0x55c92c3f8424 0x55c92c3f8120 0x55c92c46cb80 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4 0x55c92c3f99da 0x55c92c467eae 0x55c92c46702f 0x55c92c3f9aba 0x55c92c46c2c0 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4 0x55c92c46766e 0x55c92c3fa36c 0x55c92c43b7b9 0x55c92c4386d4 0x55c92c3fa571 0x55c92c469633\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55cb35aa8000 @  0x7fa43f5fc1e7 0x7fa43c0e246e 0x7fa43c132c7b 0x7fa43c13335f 0x7fa3e6e8d235 0x7fa3e6810792 0x7fa3e6810d42 0x7fa3e67c9aee 0x55c92c3f8317 0x55c92c3f8120 0x55c92c46c679 0x55c92c3f99da 0x55c92c468108 0x55c92c4671c0 0x55c92c338eb0 0x55c92c469633 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468108 0x55c92c46766e 0x55c92c3f9aba 0x55c92c468108 0x55c92c3f99da 0x55c92c468108 0x55c92c46702f 0x55c92c3fa151 0x55c92c3fa571 0x55c92c469633 0x55c92c46702f 0x55c92c3f9aba 0x55c92c467eae\n",
            "Dataset shape = [3, 128, 128]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Loading networks from \"/content/drive/MyDrive/GAN/network-snapshot-000300.pkl\"...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n",
            "\n",
            "G                     Params    OutputShape         WeightShape     \n",
            "---                   ---       ---                 ---             \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "---                   ---       ---                 ---             \n",
            "Total                 29328669                                      \n",
            "\n",
            "\n",
            "D           Params    OutputShape         WeightShape     \n",
            "---         ---       ---                 ---             \n",
            "128x128/FromRGB     1024      (?, 256, 128, 128)  (1, 1, 3, 256)  \n",
            "128x128/Conv0       590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down  1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip        131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0         2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down    2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip          262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0         2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down    2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip          262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0         2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down    2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip          262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0           2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down      2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip            262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/Conv            2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0          4194816   (?, 512)            (8192, 512)     \n",
            "Output/weight       512       (512, 1)            (512, 1)        \n",
            "Output/bias         1         (1,)                (1,)            \n",
            "---         ---       ---                 ---             \n",
            "Total       28389121                                      \n",
            "\n",
            "Building TensorFlow graph...\n",
            "Initializing logs...\n",
            "Training for 300 kimg...\n",
            "\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55cdddc66000 @  0x7fa43f5fe001 0x7fa43c0e254f 0x7fa43c132b58 0x7fa43c136b17 0x7fa43c1d5203 0x55c92c3f8424 0x55c92c3f8120 0x55c92c46cb80 0x55c92c46766e 0x55c92c3fa36c 0x55c92c43b7b9 0x55c92c4386d4 0x55c92c3fa571 0x55c92c469633 0x55c92c46702f 0x55c92c338e2b 0x55c92c469633 0x55c92c3f99da 0x55c92c468108 0x55c92c3f99da 0x55c92c468108 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4 0x55c92c46702f 0x55c92c3fa36c 0x55c92c3fa571 0x55c92c469633 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55ceddc66000 @  0x7fa43f5fc1e7 0x7fa43c0e246e 0x7fa43c132c7b 0x7fa43c13335f 0x7fa43c1d5103 0x55c92c3f8424 0x55c92c3f8120 0x55c92c46cb80 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4 0x55c92c3f99da 0x55c92c467eae 0x55c92c46702f 0x55c92c3f9aba 0x55c92c46c2c0 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468cd4 0x55c92c46766e 0x55c92c3fa36c 0x55c92c43b7b9 0x55c92c4386d4 0x55c92c3fa571 0x55c92c469633\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55ceddc66000 @  0x7fa43f5fc1e7 0x7fa43c0e246e 0x7fa43c132c7b 0x7fa43c13335f 0x7fa3e6e8d235 0x7fa3e6810792 0x7fa3e6810d42 0x7fa3e67c9aee 0x55c92c3f8317 0x55c92c3f8120 0x55c92c46c679 0x55c92c3f99da 0x55c92c468108 0x55c92c4671c0 0x55c92c338eb0 0x55c92c469633 0x55c92c46702f 0x55c92c3f9aba 0x55c92c468108 0x55c92c46766e 0x55c92c3f9aba 0x55c92c468108 0x55c92c3f99da 0x55c92c468108 0x55c92c46702f 0x55c92c3fa151 0x55c92c3fa571 0x55c92c469633 0x55c92c46702f 0x55c92c3f9aba 0x55c92c467eae\n",
            "network-final                  time 21m 20s      pr50k3_precision 0.5504     pr50k3_recall 0.0301\n",
            "dnnlib: Finished training.training_loop.training_loop() in 22m 42s.\n"
          ]
        }
      ],
      "source": [
        "!python3 run_training.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZStiv4gq-_5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2870a0d7-8b88-45e1-a682-8dcb96f019b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "28%4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q7IvT53L92W2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f02044f-47e9-460b-af90-d6758c535a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-MRrRiwlDQSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copy of Reproducibility_model_trainer_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}